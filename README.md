# Artificial-Neural-Networks

An artificial neural network, usually simply called neural network, is an interconnected group of nodes, inspired by a simplification of neurons in a brain. Neural networks consist of input and output layers, as well as (in most cases) hidden layer(s) consisting of units that transform the input into something that the output layer can use. 

Although neural networks (also known as "perceptrons") have been around since the 1940s, they have only become a significant part of artificial intelligence in the last few decades. This is due to the arrival of a technique called “backpropagation”, which allows networks to adjust their hidden layers of neurons in situations where the outcome doesn’t match what the creator is hoping for — like a network designed to recognize dogs, which misidentifies a cat, for example.  Another important move forward was the introduction of deep learning neural networks, in which various layers of a multilayer network extract different features before it can identify what it is searching for.

There are multiple types of neural network, each of which come with their own specific use cases and levels of complexity. In this project, we study three networks: Variational Autoencoders, Deep Convolutional Generative Adversarial Networks and Capsule Generative Adversarial Networks.

## Project Paper and Results
